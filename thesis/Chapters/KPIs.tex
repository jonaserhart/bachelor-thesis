\chapter{Exploration of Performance Indicators} 

\label{Chapter4} 

\section{Methods of exploring the relevance of KPIs}

\subsection{Survey}

\subsubsection{Distribution}

A comprehensive survey was designed to gain insights 
into the perception and practical application of various KPIs in 
enhancing team performance. 
The survey was distributed among professionals within the partnering 
company and extended to colleagues working in other corporate 
environments to ensure a varied set of responses.
The survey was distributed electronically, ensuring 
ease of access for all participants. 

\subsubsection{Questions}

Two sections in the survey help find out more about the respondent and their views on KPIs. 
The following questions are presented to the participant:

\begin{itemize}
    \item Section 1: SCRUM experience
    \begin{itemize}
        \item Question 1: \textit{Do you have experience with SCRUM?}
        
        This question's purpose is to determine whether the respondent has had any experience with the SCRUM framework. This is to make sure that the following questions are only answered by experienced people.
        \item Question 2: \textit{How many years of experience do you have with SCRUM?}
        
        For those who have experience with SCRUM, this question aims to quantify the duration of their involvement. It helps in understanding how different levels of experience change the subsequent answers.
        \item Question 3: \textit{Which SCRUM roles have you primarily taken on?}
        
        This question is designed to identify the specific roles that participants have assumed within SCRUM teams.
    \end{itemize}

    \item Section 2: Evaluation of KPIs in the SCRUM context
    \begin{itemize}
        \item Question 4: \textit{How helpful do you find the following KPIs for SCRUM purposes?}
        
        Participants are presented with a list of KPIs and are asked to evaluate their helpfulness in the context of SCRUM. This question aims to gather data on the perceived relevance of each KPI.
        The list of KPIs includes the following items:

        \begin{itemize}
            \item Capacity: How many Story Points can a Team theoretically do in a Sprint?
            \item Number of planned tickets
            \item Number of done tickets
            \item Commitment: Story Points planned for a Sprint
            \item Overplanning ratio: Planned Story Points / Capacity
            \item Amount of done Story Points
            \item Velocity: Planned Story Points / Done Story Points
            \item Blocker Tickets: Number of 'emergency' tickets that got added during a Sprint
            \item Blocker Tickets done: Number of 'emergency' tickets that got done in the Sprint
            \item Additional Tickets: Tickets that got added unexpectedly during the Sprint
            \item Open Story Points: How many story points are not done at the end of a Sprint and what state are they in?
            \item Removed tickets: Tickets that got removed during a Sprint
        \end{itemize}

        \item Question 5: \textit{Is there a KPI not listed in our survey that you find helpful in the SCRUM context? If yes, please describe it.}

        This open-ended question allows respondents to identify and describe any additional KPIs not covered in the survey but deemed valuable in SCRUM.
    \end{itemize}
\end{itemize}

The results of the survey are presented later in section \ref{kpi-survey-results}.

\subsection{Criteria of evaluation} \label{CriteriaKPIEvaluation}

The evaluation of the helpfulness of a KPI is a multifaceted process.
In the context of this thesis, 
the criteria for evaluating the helpfulness of a KPI are the responses from the survey.
Below are the details of each criterion that may be considered when evaluating the helpfulness of a KPI:

\subsubsection{Quantifiable Impact}

A KPI is considered helpful if it yields quantifiable improvements 
in team performance, project delivery, or other relevant areas.

\subsubsection{Feasibility and accessibility}
The ease of measuring data for a KPI is essential. 
KPIs that require complex, time-consuming, or costly processes 
to measure may not be considered helpful.

\subsubsection{Clarity}

A helpful KPI is clear and easily understood 
by all team members. 
It should communicate information that aids in 
decision-making and performance improvement without ambiguity.

\subsubsection{Actionability}
The KPI should lead to actionable insights. 
It is considered helpful if the data collected and 
analyzed can be used to inform decisions and actions 
that enhance performance.

\subsubsection{Relevance over time}
The KPI's ability to remain relevant over an extended period is vital. 
It should adapt to a changing project and organization.

\subsection{Approach}\label{approach-kpi-explore}

Data from the survey is analyzed using analytical tools and techniques. 
Each KPI is scored based on its adherence to the criteria.

This comprehensive approach gives a feeling of what 
KPIs contribute tangible value to SCRUM practices and 
team performance and may be classified as more helpful. 
As has been argued in this thesis many times, 
there is no one-fits-all solution when it comes to analyzing SCRUM processes. 
That's why the purpose of this section is not to classify 
KPIs as helpful or not helpful but rather to get a feel for how this 
helpfulness can be subjectively evaluated to 
decide how to use the KPI in practice. 

\subsection{Expected outcome}
In anticipation of the survey results, 
a hypothesis is formulated to guide the analysis process. 
It is predicted that there will be a notable diversity in the 
KPIs preferred by different teams. 
This diversity is expected to highlight the participant's 
preference for clear and actional KPIs. Furthermore, 
it is hypothesized that most of the quantifiable KPIs 
favored by teams are not 'standard' or widely available. 
This means that they can not be read simply by looking at a 
SCRUM board but have to be computed separately.
This expected outcome will be refuted or validated as the 
detailed analysis of the survey data unfolds. 

\newpage

\section{Exploration of KPIs}

This section will lay out the data collected by the survey and discuss how it fits the expected outcome. 
It will also evaluate specific KPIs according to the criteria listed in section \ref{CriteriaKPIEvaluation}.
For this process KPIs will be selected from the survey data that had outliers in ratings to find reasons why that may be the case. 

\subsection{Survey data}\label{kpi-survey-results}

The survey was filled out by 64 participants of which 49 filled out the survey until the end and were relevant to this thesis. Irrelevant entries included people who did not have any experience with SCRUM. The data was exported and analyzed in different ways.

\subsubsection{Participants}

The participants were, for the most part, very experienced in SCRUM. 
26 stated that they used SCRUM for more than 4 years and 21 people chose an option placing them in the 1-4 years category, 
leaving only about 6\% for the category that has less than one year of experience in SCRUM. 
A pie graph in figure \ref{fig:scrum_experience_pie_chart} displays these results. 
SCRUM roles were distributed among the respondents in the following way: 
As expected about 68\% were SCRUM team members like developers and QA. 
The amount of SCRUM masters and product owners was about the same with 30.61\% product owners and 28.57\% 
SCRUM masters. 
Note that the participants could also select multiple SCRUM roles. 
That's why the total of all selected roles is 67 and not 49. 
The distribution of the roles is visualized in figure \ref{fig:scrum_roles_bar_chart}. 
Other options chosen for this question include \textit{Observer}, \textit{Product manager} \textit{Trainer}, and \textit{Observer of product development}.

\begin{figure}[!h]
    \centering
    \begin{tikzpicture}
        \pie[text=legend, color={mutedBlue, mutedGreen, mutedCoral, mutedPeach}]{
            6.12/less than 1 year (A1),
            14.29/1-2 years (A2),
            26.53/2-4 years (A3),
            53.06/4+ years (A4)
        }
    \end{tikzpicture}
    \caption{Answers to Question 2: How many years of experience do you have with SCRUM?}
    \label{fig:scrum_experience_pie_chart}
\end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
            enlargelimits=0.15,
            legend style={at={(0.5,-0.2)}, anchor=north,legend columns=-1},
            ylabel={Count},
            symbolic x coords={Product Owner, SCRUM Team Member, SCRUM Master, Other},
            nodes near coords,
            nodes near coords align={vertical},
            x tick label style={rotate=45,anchor=east},
            every node near coord/.append style={text=black, font=\bfseries},
            ]
            \addplot+[fill=mutedBlue,draw=mutedBlue,text=mutedBlue] coordinates {(Product Owner,15)};
            \addplot+[fill=mutedGreen, draw=mutedGreen, text=mutedGreen] coordinates {(SCRUM Team Member,33)};
            \addplot+[fill=mutedCoral,draw=mutedCoral,text=mutedCoral] coordinates {(SCRUM Master,14)};
            \addplot+[fill=mutedPeach,draw=mutedPeach,text=mutedPeach] coordinates {(Other,5)};
        \end{axis}
    \end{tikzpicture}
    \caption{Answers to Question 3: Which SCRUM roles have you primarily taken on?}
    \label{fig:scrum_roles_bar_chart}
\end{figure}

\subsubsection{KPIs}

The biggest and most important part of the survey is the assessment 
of the perceived helpfulness of KPIs. 
The chosen ratings for each KPI follow a certain pattern that can be 
seen when calculating the average value. 
Some are perceived as more helpful like \textit{Capacity}, \textit{Planned Story Points} or \textit{Blocker Tickets}. 
Other KPIs like \textit{Planned Tickets} and \textit{Done Tickets} had mixed ratings and an average of about 2.8. 
Every rating was used on each KPI at least once which reinforces the idea that different teams and people require different KPIs. 
This can be seen by finding the maximum and minimum ratings for each KPI. 
These data points are documented in table \ref{tab:kpi_ratings}.

Some of the participants also decided to fill out the open-ended question at the end to bring in their own thoughts on what KPIs are helpful. Twelve of the respondents filled out this survey question. Since some answers were in German, they were translated into English to facilitate a universal understanding. The raw responses were then reduced to extract essential information, including the KPI name or a short description, the method of computation, and a detailed explanation where available. This process transformed the raw, verbose survey answers into concise, informative summaries of each proposed KPI. 

\begin{enumerate}
    \item \textbf{Quality of Refinements}
    \begin{itemize}
        \item \textit{Computation:} Compare the ratio of estimated to actual story points per ticket.
        \item \textit{Description:} Measures the accuracy of estimations made during refinements by comparing estimated story points to the actual story points required.
    \end{itemize}
    
    \item \textbf{Inter-Team Dependency Satisfaction}
    \begin{itemize}
        \item \textit{Computation:} Assess the KPI requirements of other teams and measure how well those are met.
        \item \textit{Description:} Evaluates how effectively a team meets the KPI requirements of other dependent teams.
    \end{itemize}

    \item \textbf{Pull Request and Release Count}
    \begin{itemize}
        \item \textit{Computation:} Count the number of pull requests for tickets in the sprint and the number of releases during/after the sprint.
        \item \textit{Description:} Monitors the development and deployment pace by counting pull requests and releases.
    \end{itemize}
    
    \item \textbf{Team Satisfaction and Bug to User Story Ratio}
    \begin{itemize}
        \item \textit{Computation:} Measure team satisfaction and compare the number of bugs to user stories in the backlog.
        \item \textit{Description:} Assesses team morale and the quality of work based on the prevalence of bugs.
    \end{itemize}

    \item \textbf{Story Stability}
    \begin{itemize}
        \item \textit{Computation:} Track changes made to the story during the sprint.
        \item \textit{Description:} Measures the frequency and extent of modifications to stories during development.
    \end{itemize}

    \item \textbf{QA Rejection Rate}
    \begin{itemize}
        \item \textit{Computation:} Calculate the frequency of issues sent back from QA.
        \item \textit{Description:} Assesses the quality of work based on how often QA rejects issues.
    \end{itemize}

    \item \textbf{Completion Rate}
    \begin{itemize}
        \item \textit{Computation:} Compare implemented story points to committed story points.
        \item \textit{Description:} Evaluates the teamâ€™s ability to complete committed work.
    \end{itemize}

    \item \textbf{Cycle Time, Lead Time, Predictability Measure}
    \begin{itemize}
        \item \textit{Computation:} Measure the time it takes to complete tasks and the percentage of stories accepted in the committed iteration.
        \item \textit{Description:} Evaluates efficiency and predictability in task completion and story acceptance.
    \end{itemize}

    \item \textbf{Technical Debt Ratio}
    \begin{itemize}
        \item \textit{Computation:} Measure the amount of technical debt or maintenance work included in each sprint.
        \item \textit{Description:} Ensures a balance between new feature development and maintenance work.
    \end{itemize}

    \item \textbf{Cycle Time and Throughput}
    \begin{itemize}
        \item \textit{Computation:} Avoid using tickets done per sprint; instead, measure cycle time and throughput.
        \item \textit{Description:} Provides a more accurate representation of velocity and productivity.
    \end{itemize}

    \item \textbf{User Stories to Technical Debt Ratio}
    \begin{itemize}
        \item \textit{Computation:} Compare the number of user stories implemented to the amount of technical debt addressed.
        \item \textit{Description:} Maintains a balance between feature development and technical debt resolution.
    \end{itemize}

    \item \textbf{Accepted Tickets Ratio}
    \begin{itemize}
        \item \textit{Computation:} Count tickets delivered and accepted by the Product Owner.
        \item \textit{Description:} Avoids a false sense of achievement by only counting tickets that are both delivered and accepted.
    \end{itemize}
\end{enumerate}


\begin{table}[!h]
    \centering
    \caption{KPI Ratings}
    \begin{tabular}{lcccc}
        \toprule
        KPI Abbreviation & Average Rating & Minimum Rating & Maximum Rating \\
        \midrule
        Capacity & 3.96 & 1.0 & 5.0 \\
        Done story points & 3.76 & 1.0 & 5.0 \\
        Commitment & 3.71 & 1.0 & 5.0 \\
        Velocity & 3.71 & 1.0 & 5.0 \\
        Open Story Points & 3.63 & 1.0 & 5.0 \\
        Blocker Tickets & 3.20 & 1.0 & 5.0 \\
        Overplanning ratio & 3.04 & 1.0 & 5.0 \\
        Additional Tickets & 2.90 & 1.0 & 5.0 \\
        Done Tickets & 2.85 & 1.0 & 5.0 \\
        Planned Tickets & 2.82 & 1.0 & 5.0 \\
        Blocker Done & 2.82 & 1.0 & 5.0 \\
        Removed Tickets & 2.45 & 1.0 & 5.0 \\
    \end{tabular}
    \decoRule
    \caption[SCRUM metric importance by activities]{SCRUM metric importance by activities}
    \label{tab:kpi_ratings}
\end{table}

\subsubsection{Correlations and outliers in the data}

There were no significant correlations in the survey data except ratings of KPIs that were similar. 
When computing the correlation matrix, 
two pairs of ratings for KPIs showed a high (>0.75) correlation. 
The statements that can be inferred by this fact is that the KPIs \textit{Number of planned Tickets} and \textit{Number of done Tickets} are often used together as well as \textit{Blocker Tickets} and \textit{Blocker Tickets done}. 
It makes sense to use these KPIs together so this correlation is not surprising.

Some KPIs discussed in the survey are going to be discussed further due to outliers in their ratings.

\paragraph{\textbf{Capacity}:} This KPI scored the highest on the survey. Reasons for that may be that it can directly influence how well a sprint planning goal is met. If the KPI is known at the sprint start, developers have an understanding of how much work they can complete during the sprint. It can be easily computed by averaging the amount of work done in past sprints. Ideally, it is measured in a universally applicable unit like story points. One drawback of this KPI is that it requires very much pre-existing data to be accurate. Averaging the amount of work done over a few sprints may lead to wrong conclusions. But over time, more and more measurements can be collected and this number should be more accurate.

\paragraph{\textbf{Done story points}:} A value representing the amount of work that got done in a sprint. The second most popular KPI \textit{Done story points} gives quick feedback to the development team and is easy to compute by counting the story points in every closed ticket. In combination with other KPIs, this can be an indicator of how well the sprint goal was reached or how much of the planned work is still not done. 

\paragraph{\textbf{Blocker Tickets \& Blocker Done}:} With a rating of about 3.20 and 2.82 these KPIs place sixth and second to last in the survey. The KPI \textit{Blocker Tickets} gives insight into how many emergency tickets were added after the planning. It is a metric of how unpredictable a sprint can be. If there are many blocker tickets in a sprint, this usually means planned work is left behind to prioritize the urgent blockers. It is very easy to compute since it is just a count of tickets that were marked as \textit{urgent} or \textit{blocker}. If this metric is often high, the development team might be able to plan less work before the sprint in order to leave some room for emergency tickets. The KPI \textit{Blocker Done} measures how many of those tickets were completed during the sprint. These two KPIs together can be important clues for planning a sprint. The greater the difference in values, the less leeway there was in the planning for emergency tickets. Among the opinions of the participants, these KPIs are not as helpful as others listed. 

\paragraph{\textbf{Removed Tickets}:} This KPI scored the lowest on the survey with a rating of 2.45. It computes a list of tickets that got removed during a sprint. This removal may be the result of a prioritized ticket being moved into the sprint retroactively for example. The KPI is hard to compute at the end of the sprint and requires a snapshot of the sprint before it was started. The value of this KPI may be relevant to some teams that have to explain to a customer why a ticket was not done in the sprint although it was planned, but otherwise, its applications seem to be limited.

\section{Practical implications}

What are the practical implications for SCRUM teams today considering the data gathered in this short research chapter? 
On the one hand, it seems as if the data collected supports the original hypotheses that quantifiable KPIs 
favored by teams are not 'basic' or 'commonly used' KPIs as labeled by literature discussed in section \ref{SOTAStudies}.
This is evident in two parts of the survey evaluation. 
Firstly, the fact that many suggestions for KPIs were made in response to question 5 and secondly that there were mixed ratings
for every KPI. This supports the original hypothesis and matches the expected outcome.
On the other hand, new insights were also gained. 
Most KPIs that are popular, as stated in studies discussed earlier in the literary review in section \ref{SOTAStudies}, 
are still favorites with most people. 
Unsurprisingly, which KPIs are seen as helpful depends on the years of experience and the SCRUM role. This is also supported by
a thesis discussed in section \ref{SOTAStudies} \parencite{AgileProjectHealthIndicatorsThesis}.

Overall, this exploration leads to the conclusion that different teams require different KPIs that cannot be modeled as static
if provided by a single application for multiple teams and different projects. 
Thus there seems to be a need for custom KPIs that cater to the specific requirements of a team.  